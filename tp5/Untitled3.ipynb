{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "import pickle as pkl\n",
    "import scipy.stats\n",
    "\n",
    "datapath = 'ml-100k/'\n",
    "filename = \"u.data\"\n",
    "\n",
    "def read_lines(filename):\n",
    "    return list(row[0:3] for row in list(csv.reader( open(filename, 'rb'), delimiter='\\t')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_indexed(data):\n",
    "    user_index = {}\n",
    "    for [user_id, item_id, rating] in data:\n",
    "        if user_id not in user_index:\n",
    "            user_index[user_id] = {item_id: rating}\n",
    "        else:\n",
    "            user_index[user_id][item_id] = rating\n",
    "    return user_index\n",
    "\n",
    "\n",
    "def item_indexed(data):\n",
    "    item_index = {}\n",
    "    for [user_id, item_id, rating] in data:\n",
    "        if item_id not in item_index:\n",
    "            item_index[item_id] = {user_id: rating}\n",
    "        else:\n",
    "            item_index[item_id][user_id] = rating\n",
    "    return item_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, train_prop):\n",
    "    p = np.random.permutation(data)\n",
    "    train_size = int(round(train_prop * len(p) ))\n",
    "    return p[:train_size], p[train_size:] #train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineUser():\n",
    "    def fit(self, user_index):\n",
    "        self.model = {}\n",
    "        for user in user_index.keys():\n",
    "            self.model[user] = 0\n",
    "            for item in user_index[user].keys():\n",
    "                self.model[user] += int(user_index[user][item])\n",
    "            self.model[user] /= len( user_index[user] )\n",
    "    def predict(self, lines):\n",
    "        self.pred = [self.model[u] for [u, _, _] in lines]\n",
    "        return self.pred\n",
    "    \n",
    "    def error(self, test):\n",
    "        return (( np.array(self.pred) - test ) ** 2).mean()\n",
    "\n",
    "    \n",
    "class BaselineItem():\n",
    "    def fit(self,item_index):\n",
    "        self.model = {}\n",
    "        for item in item_index.keys():\n",
    "            self.model[item] = 0\n",
    "            for user in item_index[item].keys():\n",
    "                self.model[item] += int(item_index[item][user])\n",
    "            self.model[item] /= len( item_index[item] )\n",
    "    def predict(self, lines):\n",
    "        self.pred = [self.model[i] for [_, i, _] in lines]\n",
    "        return self.pred\n",
    "    \n",
    "    def error(self, test):\n",
    "        return (( np.array(self.pred) - test ) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization():\n",
    "    def __init__(self,f, iter=100, e=0.001, lmbda=0.2):\n",
    "        self.f = f\n",
    "        self.iter = iter\n",
    "        self.e = e\n",
    "        self.lmbda = lmbda\n",
    "        \n",
    "        \n",
    "        self.p = {}\n",
    "        self.q = {}\n",
    "        self.bu = {}\n",
    "        self.bi = {}\n",
    "        \n",
    "        self.loss_history = []\n",
    "        self.pred = []\n",
    "\n",
    "    def fit(self, data):\n",
    "        t_total = 0\n",
    "        for it in xrange(self.iter):\n",
    "            loss = 0\n",
    "            t = time.time()\n",
    "            data_perm = np.random.permutation(data) # stochastique\n",
    "            for j in xrange(len(data_perm)):\n",
    "                \n",
    "                u = data_perm[j][0]\n",
    "                i = data_perm[j][1]\n",
    "                r_ui = data_perm[j][2]\n",
    "                \n",
    "                self.mu = np.random.random()\n",
    "                # init mu, p, bu ,q, bi\n",
    "                if u not in self.p:\n",
    "                    self.p[u] = np.random.rand(1,self.f)\n",
    "                    self.bu[u] = np.random.random()\n",
    "                if i not in self.q:\n",
    "                    self.q[i] = np.random.rand(self.f,1)\n",
    "                    self.bi[i] = np.random.random()\n",
    "                \n",
    "                # update\n",
    "                phi_ui = float(r_ui) - (self.mu + self.bi[i] + self.bu[u] + np.dot(self.p[u], self.q[i])[0][0])\n",
    "                self.p[u] = (1 - self.lmbda * self.e) * self.p[u] + self.e * self.q[i].T * phi_ui\n",
    "                self.q[i] = (1 - self.lmbda * self.e) * self.q[i] + self.e * self.p[u].T * phi_ui\n",
    "                self.bu[u] = (1 - self.lmbda * self.e) * self.bu[u] + self.e * phi_ui\n",
    "                self.bi[i] = (1 - self.lmbda * self.e) * self.bi[i] + self.e * phi_ui\n",
    "                self.mu = (1 - self.lmbda * self.e) * self.mu + self.e * phi_ui\n",
    "                \n",
    "                loss += phi_ui**2\n",
    "\n",
    "            t_total += (time.time() - t)\n",
    "            vitesse = (it+1) / t_total\n",
    "            if (it % 50==0):\n",
    "                print \"%d: loss=%.2f, Temps restant %.2fs\" % ( it, loss/len(data), vitesse * (self.iter - (it+1) ) )\n",
    "            self.loss_history.append(loss)\n",
    "                \n",
    "    def predict(self, lines):         \n",
    "        self.pred = [ self.mu + self.bu[u] + self.bi[i] + np.dot( self.p[u], self.q[i] )[0][0] for [u, i, _] in lines ]\n",
    "        return self.pred\n",
    "    \n",
    "    def error(self, test):\n",
    "        return (( np.array(self.pred) - test ) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données de test de départ: 20000\n",
      "Données de test supprimées: 42\n"
     ]
    }
   ],
   "source": [
    "lines = read_lines(datapath+filename)\n",
    "train_lines, test_lines = split_data(lines, 0.8)\n",
    "dep = len( test_lines )\n",
    "print \"Données de test de départ:\", dep\n",
    "users_del = set([line[0] for line in test_lines]) - set([line[0] for line in train_lines])\n",
    "films_del = set([line[1] for line in test_lines]) - set([line[1] for line in train_lines])\n",
    "test_lines = [t.tolist() for t in test_lines if t[0] not in users_del and t[1] not in films_del]\n",
    "print \"Données de test supprimées:\", dep-len( test_lines )\n",
    "\n",
    "user_index_train = user_indexed(train_lines)\n",
    "item_index_train = item_indexed(train_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur en test pour la baseline User: 1.41557270268\n",
      "Erreur en test pour la baseline Item: 1.36291211544\n"
     ]
    }
   ],
   "source": [
    "model_user = BaselineUser()\n",
    "model_user.fit(user_index_train)\n",
    "model_user.predict(test_lines)\n",
    "print \"Erreur en test pour la baseline User:\", model_user.error(np.array(test_lines, float)[:,2])\n",
    "\n",
    "model_item = BaselineItem()\n",
    "model_item.fit(item_index_train)\n",
    "model_item.predict(test_lines)\n",
    "print \"Erreur en test pour la baseline Item:\",  model_item.error(np.array(test_lines, float)[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMovieLens(path='/data/movielens'):\n",
    "    # Get movie titles\n",
    "    movies={}\n",
    "    for line in open(path+'/u.item'):\n",
    "        (id,title)=line.split('|')[0:2]\n",
    "        movies[id]=title\n",
    "    # Load data\n",
    "    prefs={}\n",
    "    for line in open(path+'/u.data'):\n",
    "        (user,movieid,rating,ts)=line.split('\\t')\n",
    "        prefs.setdefault(user,{})\n",
    "        prefs[user][movies[movieid]]=float(rating)\n",
    "    return prefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: loss=1.90, Temps restant 555.00s\n",
      "50: loss=0.91, Temps restant 520.27s\n",
      "100: loss=0.88, Temps restant 493.04s\n",
      "150: loss=0.85, Temps restant 467.27s\n",
      "200: loss=0.82, Temps restant 440.39s\n",
      "250: loss=0.79, Temps restant 413.65s\n",
      "300: loss=0.77, Temps restant 386.37s\n",
      "350: loss=0.75, Temps restant 356.80s\n",
      "400: loss=0.74, Temps restant 327.20s\n",
      "450: loss=0.73, Temps restant 293.83s\n",
      "500: loss=0.72, Temps restant 266.14s\n",
      "550: loss=0.72, Temps restant 239.19s\n",
      "600: loss=0.72, Temps restant 212.14s\n",
      "650: loss=0.71, Temps restant 185.72s\n",
      "700: loss=0.70, Temps restant 159.55s\n",
      "750: loss=0.70, Temps restant 133.24s\n",
      "800: loss=0.70, Temps restant 106.66s\n",
      "850: loss=0.69, Temps restant 79.62s\n",
      "900: loss=0.69, Temps restant 52.73s\n",
      "950: loss=0.69, Temps restant 26.06s\n",
      "k: 5,lambda: 0.05, erreur²: 1.15\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TSNE2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-0f816cd03523>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mtSNE_movies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTSNE2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_movies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'TSNE2' is not defined"
     ]
    }
   ],
   "source": [
    "# Charement du modèle entrainé\n",
    "\n",
    "nb_iter = 1000\n",
    "lmbda = 0.05\n",
    "k = 5\n",
    "\n",
    "model = MatrixFactorization(k, iter=nb_iter, lmbda=lmbda, e=1e-3)\n",
    "model.fit(train_lines)\n",
    "model.predict(test_lines)\n",
    "error = model.error(np.array(test_lines, float)[:,2])\n",
    "print \"k: %d,lambda: %.2f, erreur²: %.2f\" % (k, lmbda, error)\n",
    "     \n",
    "f = open('model.pkl', 'w')\n",
    "pkl.dump(model, f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"model.pkl\")\n",
    "model = pkl.load(f)\n",
    "f.close()\n",
    "\n",
    "movielens = user_indexed(read_lines(datapath+filename))\n",
    "\n",
    "x_movies = []\n",
    "x_users= []\n",
    "y = []\n",
    "for (movie_id, rep_movie), (user_id, rep_user) in zip( model.q.items(), model.p.items() ):\n",
    "    y.append( int(round( model.predict( [ [user_id,movie_id, 0] ] )[0] )) )\n",
    "    x_movies.append( rep_movie.squeeze() )\n",
    "    x_users.append( rep_user.squeeze() )\n",
    "\n",
    "# tSNE_movies = TSNE(learning_rate=1000,  n_iter=200).fit_transform(x_movies)\n",
    "# tSNE_users = TSNE(learning_rate=100,  n_iter=200).fit_transform(x_users)\n",
    "\n",
    "\n",
    "tSNE_movies = TSNE2(n_components=2, perplexity=30.0, learning_rate=1000.0, n_iter=200, alpha=0).fit_transform(np.array(x_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"model.pkl\")\n",
    "model = pkl.load(f)\n",
    "f.close()\n",
    "\n",
    "movielens = user_indexed(read_lines(datapath+filename))\n",
    "\n",
    "x_movies = []\n",
    "x_users= []\n",
    "y = []\n",
    "for (movie_id, rep_movie), (user_id, rep_user) in zip( model.q.items(), model.p.items() ):\n",
    "    y.append( int(round( model.predict( [ [user_id,movie_id, 0] ] )[0] )) )\n",
    "    x_movies.append( rep_movie.squeeze() )\n",
    "    x_users.append( rep_user.squeeze() )\n",
    "\n",
    "# tSNE_movies = TSNE(learning_rate=1000,  n_iter=200).fit_transform(x_movies)\n",
    "# tSNE_users = TSNE(learning_rate=100,  n_iter=200).fit_transform(x_users)\n",
    "\n",
    "\n",
    "tSNE_movies = TSNE(n_components=2, perplexity=30.0, learning_rate=1000.0, n_iter=200).fit_transform(np.array(x_movies))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
