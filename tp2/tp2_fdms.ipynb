{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_table('bluegills.txt')\n",
    "#df.info()\n",
    "#df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADx0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wcmMx\nLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvyHfiKQAAGmZJREFUeJzt3X10XHd95/H3xxYKJg92Ystx\niOXawSFdcGiQR6m9oZBCW5KWtcnpnm7oAzGb1m43i1u6x5QUH2yyZstidrt1e5rjQFInWwhNAWOd\nPZQSUiBN1w562BArDy0mAWQTIcUGQx4ax9Z3/5irZCzfkWcs3Xs1M5/XOXM889Md6TuG6ON7f7/f\n9yoiMDMzm2hW0QWYmdnM5IAwM7NUDggzM0vlgDAzs1QOCDMzS+WAMDOzVA4IMzNL5YAwM7NUDggz\nM0vVVnQBU7FgwYJYunRp0WWYmTWU/v7+pyOi43THNXRALF26lL6+vqLLMDNrKJK+W8txvsRkZmap\nHBBmZpbKAWFmZqkcEGZmlsoBYWZmqRwQZmaWygFhZmapHBBmZpaqoTfKmVlr6u3ZSefAdhbGKCPq\nYKhrE91rNhRdVtNxQJhZQ+nt2cmK/s3M0TEQLGKUuf2b6QWHxDTzJSYzayidA9vL4VBhjo7RObC9\noIqalwPCzBrKwhitMv50zpU0PweEmTWUEaU3IR3RgpwraX4OCDNrKENdm3g+2k8aez7aGeraVFBF\nzcsBYWYNpXvNBgZXbmOYDsZCDNPB4MptnqDOgCKi6BrOWKlUCt8PwsysPpL6I6J0uuN8BmFmZqkc\nEGZmlsoBYWZmqRwQZmaWKrOAkHSHpBFJgxVjV0jaJ+khSX2SrkzGJWmHpAOSHpbUlVVdZtb4ent2\nMrx1OWNb5jK8dTm9PTuLLqkpZXkGsQu4ZsLYx4APR8QVwIeS1wDXApcmj/XArRnWZWYNbLwX0yJG\nmZX0YlrRv9khkYHMAiIi7geOTBwGzkuezwW+nzxfC9wVZfuAeZIuyqo2M2tc7sWUn7y7uf4B8PeS\nPk45nP5tMn4xMFRx3MFk7KmJ30DSespnGSxZsiTTYs1s5lkYo6C0cfdimm55T1L/HvC+iOgE3gfc\nXu83iIjbIqIUEaWOjvSeLGbWvNyLKT95B8QNwOeT538LXJk8PwR0Vhy3OBkzMzuJezHlJ++A+D7w\nluT5W4FvJc97gHcnq5lWAUcj4pTLS2Zm7sWUn8zmICTdDVwNLJB0ENgC/A7wZ5LagH8lmUsAvgj8\nMnAAeA54T1Z1mVnj616zAZJAWJQ8bPplFhAR8a4qX1qZcmwAN2VVi5mZ1c87qc3MLJUDwszMUjkg\nzMwslQPCzMxSOSDMzCxV3q02zCwDvT076RzYzsIYZUQdDHVtaup9Aa32eYvigDBrcOPdTefoGCTd\nTef2b6YXmvKXZqt93iL5EpNZg2u17qat9nmhuPtf+AzCrMFV7246mn8xOWi1z1vkGZPPIMwaXMrv\nyknHG91YlV9b1cYbXZFnTM35N2pmTWs2Y3WNN7pqZ0Z53P/CAWFmDeUHVe4HUW280RV5/wsHhFmD\nezHSLyZVG290rXY/iCI/rwPCrME9O+ucusYbXavdD6LIz6typ+3GVCqVoq+vr+gyzAo1tmUus1JO\nFsZCzPrwj/IvyGY8Sf0RUTrdcT6DMGtwR3VulfHmPIOw/DggzBpetasAjXt1wGYGB4RZg5sbz1QZ\nfzbnSqzZOCDMGlyRyyCtuTkgzBrcUNcmTky4mnQiaNpln5YfB4RZgztr/6dP+Q95VjJuNhWZBYSk\nOySNSBqcMP5eSY9LekTSxyrGb5Z0QNI/S3p7VnWZNZvLjz2EJixzlcrjZlORZTfXXcBfAHeND0j6\neWAt8DMR8YKkhcn464DrgdcDrwa+Ium1EXEiw/rMrEHt3bGO7sN7mM0YJ5hF7/y1rN64q+iymk5m\nZxARcT9wZMLw7wEfjYgXkmNGkvG1wGci4oWIeBI4AFyZVW1m1rj27ljHqsO7adMYErRpjFWHd7N3\nx7qiS2s6ec9BvBb4OUkPSvq6pO5k/GJgqOK4g8mYmdlJug/vSb2k1n14TzEFNbG8bxjUBlwArAK6\ngXskXVLPN5C0HlgPsGTJkmkv0MxmtlZr912kvM8gDgKfj7JvAGPAAuAQ0Flx3OJk7BQRcVtElCKi\n1NHRnO19zay6E1V+bVUbtzOX99/oF4CfB5D0WqAdeBroAa6XdJakZcClwDdyrs2sIVVbydGsKzx6\n569lYo/RiPK4Ta8sl7neDewFLpN0UNKNwB3AJcnS188ANyRnE48A9wCPAl8CbvIKJrPazK5zvNGt\n3riLffOv43jMIgKOxyz2zb/Oq5gy4HbfZg0utsw9ZdIWyv+q1oeP5l+QzXhu923WIp7lrLrGzWrl\ngDBrcC+qva5xs1o5IMwa3Nz4SV3jZrVyQJg1uCBlAmKScbNaOSDMGtysKneOqzZuVisHhJmZpXJA\nmDW4ag0m3HjCpirvXkxmufn21hVcEi/3gHxCnbxm6+Ak72hM1WYamnkGwu2+8+EzCGtK4+Eg8dLj\nkhji21tXFF2aTZHbfefHAWFNaTwcKo2HRLNptTMIt/vOjwPCzBqK233nxwFhZg3F7b7z479Ra0pP\nqDO1JfQT6kx/QwN7MUj9rC826TYIt/vOjwPCmtJrtg6+FBLjj2ZdxdR+y1HGKj5nBIxFebwZud13\nftzu26zBja/qqZy4jcC/NK0qt/s2axFe1WNZcUCYNTiv6rGsOCDMzCyVW21Y0+rt2UnnwHYWxigj\n6mCoaxPdazYUXZZZw3BAWFPq7dnJG/pv5iydAMEiRjm//2Z6wSFhViNfYrKmtHzglnI4VDhLJ1g+\ncEtBFWXnOV5Z17hZrRwQ1pTmxTN1jTeyR1fewvE4+T/l4zGLR1c2XxhavjILCEl3SBqRdMrOJEn/\nRVJIWpC8lqQdkg5IelhSV1Z1mTWb7jUbGNXckzbKjWquL6XZlGV5BrELuGbioKRO4JeA71UMXwtc\nmjzWA7dmWJe1gBer9DKtNt7Ivr11BYvihye1Nl8UP3Rrc5uyzAIiIu4HjqR86U+B98NJN8xdC9wV\nZfuAeZIuyqo2a36vqHI/5mrjjayVWptbvnKdg5C0FjgUEd+c8KWLgcr/Nx9MxtK+x3pJfZL6RkdH\nM6rUzMxyCwhJrwL+GPjQVL5PRNwWEaWIKHV0dExPcWZmdoo8zyBeAywDvinpO8BiYEDSIuAQUNmH\neXEyZnZG9rdfkdoSen/7FcUUlKEXo8p8S5Vxs1rlFhARsT8iFkbE0ohYSvkyUldEDAM9wLuT1Uyr\ngKMR8VRetVnzeeHyX+fEhLETyXizaVP6vEqb88GmKMtlrncDe4HLJB2UdOMkh38ReAI4AHwC+E9Z\n1WWtoXNg+ym/INtUHm82I0q/1DpSXkVudsYya7UREe86zdeXVjwP4KasarHWszBGSVvRujCezr+Y\njA11beL88bYiiRdiNkMrN7GowLqs8XkntTWlVvtXtSak4cTXZmfCAWFNaahrE89H+0ljz0c7Q12b\nCqooO50D22nX8ZPG2nW8KS+nWb4cENaUutdsYHDlNobpYCzEMB0MrtzWlO0nFkb6fqBmvJxm+app\nDkLS/46I3zrdmNlM0r1mAySBsCh5NKMRdbCIU0NiRAua9jNbPmo9g3h95QtJs4GV01+OmdWrlS6n\nWb4mPYOQdDPl3c9zJP14fBg4BtyWcW1mU7J3xzq6D+9hNmOcYBa989eyeuOuosuadt1rNtALyd3z\nnmZECxha6bvn2dQpJm43TTtI+pOIuDmHeupSKpWir6+v6DJsBtq7Yx2rDu8+qYldBOybf11ThoRZ\nPST1R0TpdMfVNAcRETdLuhj4qcr3JB1bzWacn50QDlDucPqzh3dT7kRvZqdT6yT1R4HrgUfhpQ4G\nATggbEaqtgvAuwPMalfrTurrgMsi4oUsizEzs5mj1lVMTwCvyLIQs+lUbWat+W4XZJad061i+nPK\n/009Bzwk6T7gpbOIiNiYbXlmZ+bB+delTlI/OP86VhdXlllDOd0lpvElQv2UW3KbNYTVG3exdwct\nsczVLCuTBkRE3JlXIWbTrTIM2sBnDmZ1qnUV035OvXx7lPIZxraIODzdhZmZWbFqXcX0d5SXt346\neX095RWDRykvKv93016ZmZkVqtaAuCoirqp4vV/SP0XEVZJ+M4vCzMysWLUucz1H0pXjLyR1A+ck\nL4+nv8Vmmt6enQxvXc7YlrkMb11Ob8/Ooksysxms1jOI3wbukHQO5UtLPwZ+W9LZwJ9kVZxNn96e\nnazo38wcHQPBIkaZ27+ZXnBTNzNLVWsvpl7gcklzk9dHK758TxaF2fTqHNheDocKc3SsfNexJg2I\nhz/yFi4/9tBLr/e3X8EbPvj1Aisyayy1rmI6C/hVYCnQpmT3UUTcklllNq0WxmhqI6JmvevYeDhU\nbpS7/NhDPPyRtzgkzGpU6xzEHmAt5fmGZyseVUm6Q9KIpMGKse2SHpf0sKTdkuZVfO1mSQck/bOk\nt9f/UWwyI+qoMr4g50ryMTEcoNzNtfKMwswmV2tALI6I/xARH4uI/zH+OM17dgHXTBi7F1gREW8A\n/gW4GUDS6ygvnX198p6/TO5aZ9PEdx0zs3rVGhD/V9Ll9Xzj5F4RRyaMfTkixlc97QMWJ8/XAp+J\niBci4kngAHAlNm2612xgcOU2hulgLMQwHQyu3OYJajOrqtZVTG8C1kl6knKzPgGRnAmcqf8I/E3y\n/GLKgTHuYDJm06h7zYaXJqQXJY9mtb/9ilMuM0UkE9XFlWXWUGoNiGun84dK+iDl+YxPncF71wPr\nAZYsWTKdZVkTecMHv863t67gkhh6aewJdXqC2qwONV1iiojvAp3AW5Pnz9X63okkrQPeAfxGvHxD\n7EPJ9x+3OBlLq+W2iChFRKmjI33i1ay3Zyevjh8g8dLj1fEDbw40q0NNv+QlbQH+iGRSmfLNg/66\n3h8m6Rrg/cCaiHiu4ks9wPWSzpK0DLgU+Ea9399s3KT7PsysJvXccvSNwABARHxf0rmTvUHS3cDV\nwAJJB4EtlAPmLODeZC/Fvoj43Yh4RNI9lO95fRy4KSJOpH9ns9NrtX0fZlmoNSCORURICoCkxcak\nIuJdKcO3T3L8R4CP1FiP2aRG1MEiRlPGFzT15LzZdKp1HuEeSTuBeZJ+B/gK8InsyjKbmicveBMx\n4Q4mEeVxM6tNrb2YPi7pFyk36bsM+FBE3JtpZWZTsOzIA6k7qZcdeaCYgswaUK2XmEgCwaFgDcFz\nEGZTN2lASPoJp95qFF7eKHdeJlWZTZHnIMymbtI5iIg4NyLOS3mc63Cwmcy9p8ym7ow2u5nNdO49\nZTZ1iolLPRpIqVSKvr6+osswM2sokvojonS643wGYWZmqWpexWSNb++OdXQf3sNsxjjBLHrnr2X1\nxl1Fl2VmM5TPIFrE3h3rWHV4N20aQ4I2jbHq8G727lhXdGlmNkM5IFpE9+E9qRvHug/vKaYgM5vx\nHBAtYjZjdY2bmTkgWsSJKv9TVxs3M/NvhxbRO39tavO63vlriynIzGY8B0SLWL1xF/vmX8fxmEUE\nHI9Z7Jt/nVcxmVlVXubaQirDoA1YXVglZtYIfAZhZmapHBBmZpbKAWFmZqkcEGZmlsoBYWZmqTIL\nCEl3SBqRNFgxdoGkeyV9K/nz/GRcknZIOiDpYUldWdVlZma1yfIMYhdwzYSxDwD3RcSlwH3Ja4Br\ngUuTx3rg1gzralm9PTsZ3rqcsS1zGd66nN6enUWXZGYzWGYBERH3A0cmDK8F7kye3wm8s2L8rijb\nB8yTdFFWtbWi3p6drOjfzCJGmSVYxCgr+jc7JMysqrznIC6MiKeS58PAhcnzi4GhiuMOJmM2TToH\ntjNHx04am6NjdA5sL6giM5vpCpukjvK9Tuu+36mk9ZL6JPWNjo5mUFlzWhjpf1cL4+mcKzGzRpF3\nQPxg/NJR8udIMn4I6Kw4bnEydoqIuC0iShFR6ujoyLTYZjKi9L+rES3IuRIzaxR5B0QPcEPy/AZg\nT8X4u5PVTKuAoxWXomwaDHVt4vloP2ns+WhnqGtTQRWZ2UyXWbM+SXcDVwMLJB0EtgAfBe6RdCPw\nXeDXksO/CPwycAB4DnhPVnW1qu41G+ilPBexMJ5mRAsYWrmJ7jUbii7NzGYoxcSbBDSQUqkUfX19\nRZdhZtZQJPVHROl0x3kntZmZpXJAmJlZKgeEmZmlckCYmVkqB4SZmaVyQJiZWarM9kHYzNPbszPZ\nBzHKiDoY6vI+CDOrzgHRIsa7uc7RMUi6uc7t30wvOCTMLJUvMbUId3M1s3o5IFqEu7maWb0cEC3C\n3VzNrF4OiBbx5AVvYmLbrYjyuJlZGgdEi1h25AGkk8ek8riZWRoHRIvwHISZ1csB0SI8B2Fm9XJA\ntAjfUc7M6uWAaBHdazYwuHIbw3QwFmKYDgZXbvMmOTOryneUMzNrMbXeUc6tNlqIezGZWT0cEC3C\nvZjMrF6eg2gR7sVkZvVyQLQI74Mws3oVEhCS3ifpEUmDku6W9EpJyyQ9KOmApL+R1H7672S18j4I\nM6tX7gEh6WJgI1CKiBXAbOB64L8DfxoRy4EfAjfmXVsz8z4IM6tXUZeY2oA5ktqAVwFPAW8FPpt8\n/U7gnQXV1pS8D8LM6pX7KqaIOCTp48D3gOeBLwP9wI8i4nhy2EHg4rxra3bdazZAEgiLkoeZWTVF\nXGI6H1gLLANeDZwNXFPH+9dL6pPUNzqaPvFqZmZTV8Qlpl8AnoyI0Yh4Efg8cBUwL7nkBLAYOJT2\n5oi4LSJKEVHq6EifeDUzs6krIiC+B6yS9CpJAt4GPAp8Ffj3yTE3AHsKqM3MzBK5B0REPEh5MnoA\n2J/UcBvwR8AfSjoAzAduz7s2MzN7WSGtNiJiC7BlwvATwJUFlGNmZim8k9rMzFI5IMzMLJUDwszM\nUjkgzMwslQPCzMxSOSDMzCyVA8LMzFI5IMzMLJUDwszMUjkgzMwslQPCzMxSFdKLaabo7dlJ58B2\nFsYoI+pgqGuT77BmZpZo2YDo7dnJiv7NzNExECxilLn9m+kFh4SZGS18ialzYHs5HCrM0TE6B7YX\nVJGZ2czSsgGxMNJvV7owns65EjOzmallA2JE6bcrHdGCnCsxM5uZWjYghro28Xy0nzT2fLQz1LWp\noIrMzGaWlg2I7jUbGFy5jWE6GAsxTAeDK7d5gtrMLKGIKLqGM1YqlaKvr6/oMszMGoqk/ogone64\nll3mCt4HYWY2mZYNCO+DMDObXCFzEJLmSfqspMclPSZptaQLJN0r6VvJn+dnWYP3QZiZTa6oSeo/\nA74UET8N/AzwGPAB4L6IuBS4L3mdGe+DMDObXO4BIWku8GbgdoCIOBYRPwLWAncmh90JvDPLOrwP\nwsxsckWcQSwDRoG/kvT/JH1S0tnAhRHxVHLMMHBhlkV4H4SZ2eSKCIg2oAu4NSLeCDzLhMtJUV57\nm7r+VtJ6SX2S+kZH0y8T1cL7IMzMJpf7PghJi4B9EbE0ef1zlANiOXB1RDwl6SLgaxFx2WTfy/sg\nzMzqV+s+iNzPICJiGBiSNP7L/23Ao0APcEMydgOwJ+/azMzsZUXtg3gv8ClJ7cATwHsoh9U9km4E\nvgv8WkG1mZkZBQVERDwEpJ3evC3vWszMLF3LNuszM7PJOSDMzCyVA8LMzFI5IMzMLJUDwszMUjX0\nDYMkjVJeEjtVC4BW6tLnz9u8Wumzgj/vmfqpiEhvSFehoQNiukjqq2VXYbPw521erfRZwZ83a77E\nZGZmqRwQZmaWygFRdlvRBeTMn7d5tdJnBX/eTHkOwszMUvkMwszMUrV0QEi6Q9KIpMGia8mDpE5J\nX5X0qKRHJP1+0TVlRdIrJX1D0jeTz/rhomvKg6TZyZ0a/0/RtWRN0nck7Zf0kKSmvjGMpHmSPivp\ncUmPSVqdy89t5UtMkt4MPAPcFREriq4na8mNmC6KiAFJ5wL9wDsj4tGCS5t2kgScHRHPSHoF8ADw\n+xGxr+DSMiXpDyl3Sj4vIt5RdD1ZkvQdoBQRTb8PQtKdwD9GxCeT2yS8KiJ+lPXPbekziIi4HzhS\ndB15iYinImIgef4T4DHg4mKrykaUPZO8fEXyaOp/DUlaDPwK8Mmia7HpI2ku8GbgdoCIOJZHOECL\nB0Qrk7QUeCPwYLGVZCe53PIQMALcGxFN+1kT/wt4PzBWdCE5CeDLkvolrS+6mAwtA0aBv0ouH35S\n0tl5/GAHRAuSdA7wOeAPIuLHRdeTlYg4ERFXAIuBKyU17WVESe8ARiKiv+hacvSmiOgCrgVuSi4Z\nN6M2oAu4NSLeCDwLfCCPH+yAaDHJ9fjPAZ+KiM8XXU8ektPxrwLXFF1Lhq4C1iTX5T8DvFXSXxdb\nUrYi4lDy5wiwG7iy2IoycxA4WHEG/FnKgZE5B0QLSSZubwcei4j/WXQ9WZLUIWle8nwO8IvA48VW\nlZ2IuDkiFkfEUuB64B8i4jcLLiszks5OFlqQXG75JaApVyNGxDAwJOmyZOhtQC4LSwq5J/VMIelu\n4GpggaSDwJaIuL3YqjJ1FfBbwP7k2jzAH0fEFwusKSsXAXdKmk35H0L3RETTL/1sIRcCu8v/5qEN\n+HREfKnYkjL1XuBTyQqmJ4D35PFDW3qZq5mZVedLTGZmlsoBYWZmqRwQZmaWygFhZmapHBBmZpbK\nAWFmZqkcEGZmlsoBYXaGJH0haRT3yHizOEk3SvoXSV+T9AlJf5GMd0j6nKTe5HFVsdWbnZ43ypmd\nIUkXRMSRpJVHL/B24J8o98n5CfAPwDcj4j9L+jTwlxHxgKQlwN9HxL8prHizGrR0qw2zKdoo6brk\neSflNiZfj4gjAJL+Fnht8vVfAF6XtIYAOE/SORX3rDCbcRwQZmdA0tWUf+mvjojnJH2NcjPAamcF\ns4BVEfGv+VRoNnWegzA7M3OBHybh8NPAKuBs4C2SzpfUBvxqxfFfptxwDQBJV+RardkZcECYnZkv\nAW2SHgb+K7APOAT8N8p36fsK5ZbMR5PjNwIlSQ9LehT43fxLNquPJ6nNptH4vEJyBrEbuCMidhdd\nl9mZ8BmE2fTamtxrYxB4EvhCwfWYnTGfQZiZWSqfQZiZWSoHhJmZpXJAmJlZKgeEmZmlckCYmVkq\nB4SZmaX6/z7G9fBEji/XAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc541d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df.info()\n",
    "#df.head(10)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = df['age']\n",
    "y = df['length']\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('lenght')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#renvoi nb-1 polynomes de degres 1 à nb\n",
    "def init_list_poly(X_train,y_train,max_deg):\n",
    "    list_poly = []\n",
    "    #initilaise nb polynomes et les place dans list_poly\n",
    "    for j in range(1,max_deg+1):\n",
    "        poly = np.polyfit(X_train, y_train, j)\n",
    "        list_poly.append(poly)\n",
    "    return list_poly\n",
    "\n",
    "#renvoi la liste des mse pour une liste de polynomes donnée\n",
    "def mse(X_train, y_train, X_test, y_test, max_deg):\n",
    "    #dictionnaire {resultat : polynome}\n",
    "    mse = []\n",
    "    x_test = X_test.values\n",
    "    list_poly = init_list_poly(X_train,y_train,max_deg)\n",
    "    for poly in list_poly:\n",
    "        m = 0\n",
    "        y_pred = []\n",
    "        #pour chaque polynome dans z on evalue\n",
    "        for k in range(len(x_test)):\n",
    "            #calcul la valeur du polynome poly avec les donnees de test et le cast en int\n",
    "            res = np.polyval(poly,x_test[k]).astype(int)\n",
    "            y_pred.append(res)\n",
    "        m = (round(mean_squared_error(y_test.values, y_pred),2))\n",
    "        mse.append(m)\n",
    "    return mse\n",
    "\n",
    "#renvoi le polynome possédant le meileur score,son score et son degre\n",
    "def min_deg_poly(list_score):\n",
    "    index_min = np.argmin(list_score)\n",
    "    score_min = list_score[index_min]\n",
    "    return 'Le polynomes de degre ' + str(index_min+1) +' minimise le score avec : '+ str(score_min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le polynomes de degre 4 minimise le score avec : 274.94\n",
      "Le polynomes de degre 2 minimise le score avec : 330.87\n",
      "Le polynomes de degre 2 minimise le score avec : 207.25\n",
      "Le polynomes de degre 2 minimise le score avec : 245.88\n",
      "Le polynomes de degre 3 minimise le score avec : 264.57\n",
      "Le polynomes de degre 2 minimise le score avec : 186.75\n",
      "Le polynomes de degre 3 minimise le score avec : 331.87\n",
      "Le polynomes de degre 2 minimise le score avec : 299.51\n",
      "Le polynomes de degre 3 minimise le score avec : 242.32\n",
      "Le polynomes de degre 2 minimise le score avec : 181.82\n"
     ]
    }
   ],
   "source": [
    "#non stable car les decoupe differes\n",
    "#nb - nombre de decoupage\n",
    "#renvoi une liste contenant les sommes des scores selon le degres\n",
    "def decoupage_fixe(nb,max_deg,score):\n",
    "    list_score = [0]*(max_deg)\n",
    "    for i in range(nb):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20)\n",
    "        m = score(X_train, y_train, X_test, y_test, max_deg)\n",
    "        for i in range(len(m)):\n",
    "            list_score[i] += m[i]\n",
    "    return list_score\n",
    "\n",
    "#resultat non stable car les découpages sont tout le temps differents\n",
    "#decommenter les 2 lignes suivantes pour resultats avec des polynomes de degres jusqu'a 4 et 2 découpages\n",
    "#for i in range(10):\n",
    "#     print(min_deg_poly(decoupage_fixe(2,4,mse)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le polynomes de degre 2 minimise le score avec : 1212.35\n",
      "Le polynomes de degre 2 minimise le score avec : 1273.26\n",
      "Le polynomes de degre 2 minimise le score avec : 1213.51\n",
      "Le polynomes de degre 2 minimise le score avec : 1247.47\n",
      "Le polynomes de degre 2 minimise le score avec : 1230.84\n",
      "Le polynomes de degre 2 minimise le score avec : 1207.34\n",
      "Le polynomes de degre 2 minimise le score avec : 1219.16\n",
      "Le polynomes de degre 2 minimise le score avec : 1262.04\n",
      "Le polynomes de degre 2 minimise le score avec : 1258.87\n",
      "Le polynomes de degre 2 minimise le score avec : 1214.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "#non stable car les decoupes differes\n",
    "def cross_validation(n_folds,max_deg,score):\n",
    "    cv = KFold(n=len(df),n_folds=n_folds,shuffle=True)\n",
    "    list_score = [0]*(max_deg)\n",
    "    for training_set, test_set in cv:\n",
    "        X_train = x[training_set]\n",
    "        y_train = y[training_set]\n",
    "        X_test = x[test_set]\n",
    "        y_test = y[test_set]\n",
    "        m = score(X_train, y_train, X_test, y_test, max_deg)\n",
    "        for i in range(len(m)):\n",
    "            list_score[i] += m[i]\n",
    "    return np.around(list_score,2)\n",
    "\n",
    "#resultat pseudo-stable car les découpages sont differents mais plus stable que le decoupage fixe\n",
    "#decommenter les 2 lignes suivantes pour resultats avec des polynomes de degres jusqu'a 4 et 10 découpages\n",
    "#for i in range(10):\n",
    "#     print(min_deg_poly(cross_validation(10,4,mse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le polynomes de degre 2 minimise le score avec : 9432.0\n",
      "Le polynomes de degre 2 minimise le score avec : 9432.0\n",
      "Le polynomes de degre 2 minimise le score avec : 9432.0\n",
      "Le polynomes de degre 2 minimise le score avec : 9432.0\n",
      "Le polynomes de degre 2 minimise le score avec : 9432.0\n",
      "Le polynomes de degre 2 minimise le score avec : 9432.0\n",
      "Le polynomes de degre 2 minimise le score avec : 9432.0\n",
      "Le polynomes de degre 2 minimise le score avec : 9432.0\n",
      "Le polynomes de degre 2 minimise le score avec : 9432.0\n",
      "Le polynomes de degre 2 minimise le score avec : 9432.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "#stable car tout le temps la meme decoupe \n",
    "def leave_one_out(max_deg, score):\n",
    "    #l'implementation avec un dictionnaire pose un probleme avec LeaveOneOut. En effet un dictionnaire ne peut stocker deux clefs identiques.\n",
    "    # On a alors un dictionnaire de taille 20 alors qu'on devrait en avoir un de taille 78(taille de df)\n",
    "    list_score = [0]*(max_deg)\n",
    "    for train, test in loo.split(df):\n",
    "        X_train = x[train]\n",
    "        y_train = y[train]\n",
    "        X_test = x[test]\n",
    "        y_test = y[test]\n",
    "        m = score(X_train, y_train, X_test, y_test, max_deg)\n",
    "        for i in range(len(m)):\n",
    "            list_score[i] += m[i]\n",
    "    return list_score\n",
    "\n",
    "#resultat tout le temps stable car les decoupes sont toutes les memes\n",
    "#decommenter les 2 lignes suivantes pour resultats avec des polynomes de degres jusqu'a 4\n",
    "#for i in range(10):\n",
    "#       print(min_deg_poly(leave_one_out(4,mse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoupage fixe : Le polynomes de degre 2 minimise le score avec : 278.8\n",
      "Cross validation : Le polynomes de degre 2 minimise le score avec : 336.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n",
      "c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave one out : Le polynomes de degre 2 minimise le score avec : nan\n",
      "Decoupage fixe : Le polynomes de degre 2 minimise le score avec : 283.15\n",
      "Cross validation : Le polynomes de degre 2 minimise le score avec : 338.9\n",
      "Leave one out : Le polynomes de degre 2 minimise le score avec : nan\n",
      "Decoupage fixe : Le polynomes de degre 2 minimise le score avec : 275.49\n",
      "Cross validation : Le polynomes de degre 2 minimise le score avec : 340.36\n",
      "Leave one out : Le polynomes de degre 2 minimise le score avec : nan\n",
      "Decoupage fixe : Le polynomes de degre 4 minimise le score avec : 276.14\n",
      "Cross validation : Le polynomes de degre 2 minimise le score avec : 338.95\n",
      "Leave one out : Le polynomes de degre 2 minimise le score avec : nan\n",
      "Decoupage fixe : Le polynomes de degre 3 minimise le score avec : 282.26\n",
      "Cross validation : Le polynomes de degre 2 minimise le score avec : 338.24\n",
      "Leave one out : Le polynomes de degre 2 minimise le score avec : nan\n",
      "Decoupage fixe : Le polynomes de degre 2 minimise le score avec : 274.6\n",
      "Cross validation : Le polynomes de degre 2 minimise le score avec : 336.3\n",
      "Leave one out : Le polynomes de degre 2 minimise le score avec : nan\n",
      "Decoupage fixe : Le polynomes de degre 2 minimise le score avec : 277.99\n",
      "Cross validation : Le polynomes de degre 2 minimise le score avec : 339.13\n",
      "Leave one out : Le polynomes de degre 2 minimise le score avec : nan\n",
      "Decoupage fixe : Le polynomes de degre 2 minimise le score avec : 275.57\n",
      "Cross validation : Le polynomes de degre 2 minimise le score avec : 338.91\n",
      "Leave one out : Le polynomes de degre 2 minimise le score avec : nan\n",
      "Decoupage fixe : Le polynomes de degre 2 minimise le score avec : 285.27\n",
      "Cross validation : Le polynomes de degre 2 minimise le score avec : 336.35\n",
      "Leave one out : Le polynomes de degre 2 minimise le score avec : nan\n",
      "Decoupage fixe : Le polynomes de degre 3 minimise le score avec : 281.38\n",
      "Cross validation : Le polynomes de degre 2 minimise le score avec : 334.47\n",
      "Leave one out : Le polynomes de degre 2 minimise le score avec : nan\n"
     ]
    }
   ],
   "source": [
    "#AIC citerion\n",
    "#renvoi la liste des aic pour une liste de polynomes donnée\n",
    "def aic(X_train, y_train, X_test, y_test, max_deg):\n",
    "    #dictionnaire {resultat : polynome}\n",
    "    aic = []\n",
    "    x_test = X_test.values\n",
    "    k= max_deg\n",
    "    n = len(x_test)\n",
    "    list_poly = init_list_poly(X_train,y_train,max_deg)\n",
    "    for poly in list_poly:\n",
    "        m = 0\n",
    "        y_pred = []\n",
    "        #pour chaque polynome dans z on evalue\n",
    "        for k in range(n):\n",
    "            #calcul la valeur du polynome poly avec les donnees de test et le cast en int\n",
    "            res = np.polyval(poly,x_test[k]).astype(int)\n",
    "            y_pred.append(res)\n",
    "        m = mean_squared_error(y_test.values, y_pred)\n",
    "        a = round(k + 2 + n/2 * np.log(2*np.pi * m),2)\n",
    "        aic.append(a)\n",
    "    return aic\n",
    "\n",
    "#aic = k + 2 +n/2+ n/2 * np.log(2 * np.pi * mse)\n",
    "#aic += n/2. * np.log(2 * np.pi * rss/n)\n",
    "#for i in range(10):\n",
    "#    print('Decoupage fixe : ' + min_deg_poly(decoupage_fixe(4,4,aic)))\n",
    "#    print('Cross validation : ' + min_deg_poly(cross_validation(10,4,aic)))\n",
    "#    # Probleme de log(0)\n",
    "#    # En effet on peut avoir des cas ou mse = 0 car on prend pratiquement toute les données pour l'apprentissage et on a donc un modéle qui colle au donnée et donc sans erreur lors du seul test si la donnée est redondante\n",
    "#    print('Leave one out : ' + min_deg_poly(leave_one_out(4,aic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoupage fixe : Le polynomes de degre 1 minimise le score 291.04\n",
      "Cross validation : Le polynomes de degre 1 minimise le score 179.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave one out : Le polynomes de degre 1 minimise le score -610.15\n"
     ]
    }
   ],
   "source": [
    "#BIC citerion\n",
    "#renvoi la liste des aic pour une liste de polynomes donnée\n",
    "def bic(X_train, y_train, X_test, y_test, max_deg):\n",
    "    #dictionnaire {resultat : polynome}\n",
    "    bic = []\n",
    "    x_test = X_test.values\n",
    "    k= max_deg\n",
    "    n = len(x_test)\n",
    "    list_poly = init_list_poly(X_train,y_train,max_deg)\n",
    "    for poly in list_poly:\n",
    "        m = 0\n",
    "        y_pred = []\n",
    "        #pour chaque polynome dans z on evalue\n",
    "        for k in range(n):\n",
    "            #calcul la valeur du polynome poly avec les donnees de test et le cast en int\n",
    "            res = np.polyval(poly,x_test[k]).astype(int)\n",
    "            y_pred.append(res)\n",
    "        m = mean_squared_error(y_test.values, y_pred)\n",
    "        b = round(2*k*np.log(n) - 2*np.log(m),2)\n",
    "        bic.append(b)\n",
    "        #print(bic)\n",
    "    return bic\n",
    "#for i in range(10):\n",
    "#    print('Decoupage fixe : ' + min_deg_poly(decoupage_fixe(4,4,bic)))\n",
    "#    print('Cross validation : ' + min_deg_poly(cross_validation(10,4,bic)))\n",
    "    # Meme Probleme de log(0) qu'avec AIC\n",
    "    # En effet on peut avoir des cas ou mse = 0 car on prend pratiquement toute les données pour l'apprentissage et on a donc un modéle qui colle au donnée et donc sans erreur lors du seul test si la donnée est redondante\n",
    "#    print('Leave one out : ' + min_deg_poly(leave_one_out(4,bic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
